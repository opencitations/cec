{
    "cit1": {
        "SECTION": "Introduction",
        "CITATION": "Density estimation is defined as the process of constructing an estimate of the probability density function (PDF), from a set of observed data [1] [2] [3].",
        "REFERENCE": "[1]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit2": {
        "SECTION": "Introduction",
        "CITATION": "Density estimation is defined as the process of constructing an estimate of the probability density function (PDF), from a set of observed data [1] [2] [3].",
        "REFERENCE": "[2]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit3": {
        "SECTION": "Introduction",
        "CITATION": "Density estimation is defined as the process of constructing an estimate of the probability density function (PDF), from a set of observed data [1] [2] [3].",
        "REFERENCE": "[3]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit4": {
        "SECTION": "Introduction",
        "CITATION": "It is a fundamental part of statistical inference and serves as the building block of many other data mining and machine learning techniques [4] [5] [6].",
        "REFERENCE": "[4]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit5": {
        "SECTION": "Introduction",
        "CITATION": "It is a fundamental part of statistical inference and serves as the building block of many other data mining and machine learning techniques [4] [5] [6].",
        "REFERENCE": "[5]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit6": {
        "SECTION": "Introduction",
        "CITATION": "It is a fundamental part of statistical inference and serves as the building block of many other data mining and machine learning techniques [4] [5] [6].",
        "REFERENCE": "[6]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit7": {
        "SECTION": "Introduction",
        "CITATION": "Traffic control, satellite monitoring and sensor networks are some of the examples [7].",
        "REFERENCE": "[7]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit8": {
        "SECTION": "Introduction",
        "CITATION": "In highdimensional spaces, sparsity of data in local neighborhoods (curse of dimensionality [3, 8]) makes the task of density estimation very difficult.",
        "REFERENCE": "[3,",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit9": {
        "SECTION": "Introduction",
        "CITATION": "In highdimensional spaces, sparsity of data in local neighborhoods (curse of dimensionality [3, 8]) makes the task of density estimation very difficult.",
        "REFERENCE": "8]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit10": {
        "SECTION": "Introduction",
        "CITATION": "Non-parametric methods are more powerful and flexible, as they eliminate the need for specifying a distribution family [3].",
        "REFERENCE": "[3]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit11": {
        "SECTION": "Introduction",
        "CITATION": "To adapt the KDE method to estimation over stream of data, the work in [9] introduces the concept of M-Kernel.",
        "REFERENCE": "[9]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit12": {
        "SECTION": "Introduction",
        "CITATION": "The concept of Cluster Kernels, introduced in [10, 11], is again based on the idea of merging similar kernels.",
        "REFERENCE": "[10,",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit13": {
        "SECTION": "Introduction",
        "CITATION": "The concept of Cluster Kernels, introduced in [10, 11], is again based on the idea of merging similar kernels.",
        "REFERENCE": "11]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit14": {
        "SECTION": "Introduction",
        "CITATION": "Unlike ùëÄ-Kernels method, Cluster Kernels are constructed based on the Epanechnikov Kernel [12], which has bounded support, and thus, lowers the evaluation cost.",
        "REFERENCE": "[12]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit15": {
        "SECTION": "Introduction",
        "CITATION": "Furthermore, this method uses a global bandwidth setting (using normal scale rule [1]), to avoid heavy computational load associated with complex bandwidth strategies.",
        "REFERENCE": "[1]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit16": {
        "SECTION": "Introduction",
        "CITATION": "The other Kernel-based method in [13] presents an adaptive version of Parzen window, viz. Tiled Parzen Window (TPW)",
        "REFERENCE": "[13]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit17": {
        "SECTION": "Introduction",
        "CITATION": "Further, in [14], the traditional wavelet density estimator (WDE) is adapted to compressed cumulative wavelet density estimator over data streams.",
        "REFERENCE": "[14]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit18": {
        "SECTION": "Introduction",
        "CITATION": "A more recent wavelet-based online estimator is proposed in [15].",
        "REFERENCE": "[15]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit19": {
        "SECTION": "Introduction",
        "CITATION": "The work in [15], however, proposes an extension to higher dimensions, but provides no experimental results in support of its applicability to higher dimensions.",
        "REFERENCE": "[15]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit20": {
        "SECTION": "Introduction",
        "CITATION": "In this paper we present a framework for online density estimation for high-dimensional data streams, based on Bayesian sequential partitioning (BSP) algorithm [16].",
        "REFERENCE": "[16]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit21": {
        "SECTION": "Introduction",
        "CITATION": "In high-dimensional spaces, where other commonly used non-parametric methods like kernel density estimation (KDE) [17] fail, BSP algorithm has shown promising results.",
        "REFERENCE": "[17]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit22": {
        "SECTION": "Introduction",
        "CITATION": "For a system with the mission of online processing on open-ended data streams, the general design criteria [18] are listed below.",
        "REFERENCE": "[18]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit23": {
        "SECTION": "Introduction",
        "CITATION": "These criteria have been widely used as metrics for the evaluation of methods of processing data streams, [19] [20] [21].",
        "REFERENCE": "[19]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit24": {
        "SECTION": "Introduction",
        "CITATION": "These criteria have been widely used as metrics for the evaluation of methods of processing data streams, [19] [20] [21].",
        "REFERENCE": "[20]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit25": {
        "SECTION": "Introduction",
        "CITATION": "These criteria have been widely used as metrics for the evaluation of methods of processing data streams, [19] [20] [21].",
        "REFERENCE": "[21]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit26": {
        "SECTION": "Introduction",
        "CITATION": "In this work, BSP method [16] is used as the core for density estimation.",
        "REFERENCE": "[16]",
        "ALIGNED SECTION": [
            "Introduction"
        ]
    },
    "cit27": {
        "SECTION": "The algorithm",
        "CITATION": "The method of BSP [16] constructs a multidimensional histogram by making sequential binary cuts in the sample space.",
        "REFERENCE": "[16]"
    },
    "cit28": {
        "SECTION": "The algorithm",
        "CITATION": "To improve the quality of density estimation, ùëÄ independent paths (sample partitions) are tried at each level [16].",
        "REFERENCE": "[16]"
    },
    "cit29": {
        "SECTION": "The algorithm",
        "CITATION": "There are (j ‚àí 1) √ó ùê∑ possibilities for the ùëóth cut, from which one is randomly picked based on some probability mass function as described in [16].",
        "REFERENCE": "[16]"
    },
    "cit30": {
        "SECTION": "The algorithm",
        "CITATION": "To resolve this issue, the original BSP algorithm in [16] defines a partition score for each partition.",
        "REFERENCE": "[16]"
    },
    "cit31": {
        "SECTION": "The algorithm",
        "CITATION": "For a partition p, consisting of j subregions, partition score is defined as follows [16]; where ùëõ ùëò is the data count in subregion ùëò, and ùëâ ùëò represents its volume.",
        "REFERENCE": "[16]"
    },
    "cit32": {
        "SECTION": "The algorithm",
        "CITATION": "ùê∑(.) refers to the Dirichlet distribution (multivariate generalization of the Beta distribution) [22] with parameters (ùõº, ùõº, ‚Ä¶, ùõº), which was used to obtain a posterior distribution for the partitions.",
        "REFERENCE": "[22]"
    },
    "cit33": {
        "SECTION": "The algorithm",
        "CITATION": "The parameter ùõΩ is associated with the prior distribution (ùëíùë•ùëù(-ùëó)) assumed for the partitions [16].",
        "REFERENCE": "[16]"
    },
    "cit34": {
        "SECTION": "The algorithm",
        "CITATION": "It has been shown in [16] that the partition score associated with a given partition is linearly and inversely related to the KL divergence between the actual density and the estimated density obtained from that partition.",
        "REFERENCE": "[16]"
    },
    "cit35": {
        "SECTION": "The algorithm",
        "CITATION": "More detailed description of our implementation of BSP algorithm is available in [23].",
        "REFERENCE": "[23]"
    },
    "cit36": {
        "SECTION": "The algorithm",
        "CITATION": "In regular BSP algorithm [16], the entire dataset is used as the sample space ùõ∫, which is then partitioned into subregions, and eventually the data count and volume of each subregion is used to produce an estimated density in each subregion.",
        "REFERENCE": "[16]"
    },
    "cit37": {
        "SECTION": "The algorithm",
        "CITATION": "According to Sklar's theorem [2], any multivariate distribution can be written in terms of univariate marginal distributions (each one obtained separately and independently), and a copula [2] which describes the dependence structure between the variables.",
        "REFERENCE": "[2]"
    },
    "cit38": {
        "SECTION": "The algorithm",
        "CITATION": "According to Sklar's theorem [2], any multivariate distribution can be written in terms of univariate marginal distributions (each one obtained separately and independently), and a copula [2] which describes the dependence structure between the variables.",
        "REFERENCE": "[2]"
    },
    "cit39": {
        "SECTION": "The algorithm",
        "CITATION": "Second, marginal CDFs are used to construct a multidimensional density partition in the standard copula ùê∂ [2] sample space.",
        "REFERENCE": "[2]"
    },
    "cit40": {
        "SECTION": "The algorithm",
        "CITATION": "Using the marginal densities, and densities obtained in the copula-transformed multidimensional sample space, the overall densities for a test data ùê≥ is computed as, where ùëì ùëë are the marginal densities, ùêπ ùëë are the corresponding marginal CDFs, and ùëê is obtained by taking the derivative of the copula ùê∂ [2].",
        "REFERENCE": "[2]"
    },
    "cit41": {
        "SECTION": "Experimental performance of BBSP",
        "CITATION": "The evaluation criteria Kullback-Leibler divergence (KLD) [2] is used as a measure of the estimation accuracy with respect to the true density.",
        "REFERENCE": "[2]"
    },
    "cit42": {
        "SECTION": "Experimental performance of BBSP",
        "CITATION": "For this purpose, we have employed the 90-dimensional ''Year Prediction MSD Dataset'' from the University of California Irvine, Machine Learning Repository [24], as an example.",
        "REFERENCE": "[24]"
    },
    "cit43": {
        "SECTION": "Experimental performance of BBSP",
        "CITATION": "The kernel bandwidth for each dimension is calculated using Silverman‚Äôs rule of thumb [1]: where ùúé ùëñ is the standard deviation of the ùëñth dimension, ùê∑ is the number of dimensions, and ùëÅ is the number of samples.",
        "REFERENCE": "[1]"
    },
    "cit44": {
        "SECTION": "Experimental performance of BBSP",
        "CITATION": "To resolve this issue, the original BSP algorithm in [16], defines a partition score for each of the ùëÄ sample partitions.",
        "REFERENCE": "[16]"
    },
    "cit45": {
        "SECTION": "Experimental performance of BBSP",
        "CITATION": "As stated before, in Section 2.1, the defined partition score divided by the number of data instances ùëÅ (hereafter denoted as PSN) is shown [16] to linearly increase with the reduction in the computed KLD.",
        "REFERENCE": "[16]"
    },
    "cit46": {
        "SECTION": "Application to streaming data",
        "CITATION": "Fig. 19 illustrates the results for a much higher dimensional (256) data stream with different underlying statistics, where the first 64 dimensions have Gaussian distributions, and the remaining dimensions have bimodal Beta distributions [22].",
        "REFERENCE": "[22]"
    }
}