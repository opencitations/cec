Evaluation metrics produced in 807.975 seconds

======= Header metadata ======= 

Evaluation on 1943 random PDF files out of 1943 PDF (ratio 1.0).

======= Strict Matching ======= (exact matches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

abstract             79.92        4.85         4.4          4.61   
authors              96.97        86.98        85.73        86.35  
first_author         98.2         93.38        91.55        92.46  
keywords             92.69        66.09        52.25        58.36  
title                95.08        78.06        76.89        77.47  

all fields           92.57        67.1         62.97        64.97   (micro average)
                     92.57        65.87        62.16        63.85   (macro average)


======== Soft Matching ======== (ignoring punctuation, case and space characters mismatches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

abstract             81.75        14.48        13.13        13.78  
authors              97.02        87.25        85.99        86.61  
first_author         98.23        93.48        91.65        92.56  
keywords             93.88        76.08        60.14        67.18  
title                96.55        85.06        83.79        84.42  

all fields           93.48        71.98        67.54        69.69   (micro average)
                     93.48        71.27        66.94        68.91   (macro average)


==== Levenshtein Matching ===== (Minimum Levenshtein distance at 0.8)

===== Field-level results =====

label                accuracy     precision    recall       f1     

abstract             93.53        76.57        69.44        72.83  
authors              98.25        93.1         91.76        92.42  
first_author         98.28        93.75        91.91        92.82  
keywords             95.4         88.82        70.22        78.43  
title                97.22        88.24        86.93        87.58  

all fields           96.54        88.26        82.82        85.46   (micro average)
                     96.54        88.1         82.05        84.82   (macro average)


= Ratcliff/Obershelp Matching = (Minimum Ratcliff/Obershelp similarity at 0.95)

===== Field-level results =====

label                accuracy     precision    recall       f1     

abstract             92.54        71.38        64.73        67.89  
authors              97.53        89.65        88.36        89     
first_author         98.2         93.38        91.55        92.46  
keywords             94.88        84.42        66.74        74.54  
title                97.04        87.41        86.1         86.75  

all fields           96.04        85.61        80.33        82.89   (micro average)
                     96.04        85.25        79.5         82.13   (macro average)

===== Instance-level results =====

Total expected instances:       1943
Total correct instances:        61 (strict) 
Total correct instances:        169 (soft) 
Total correct instances:        993 (Levenshtein) 
Total correct instances:        884 (ObservedRatcliffObershelp) 

Instance-level recall:  3.14    (strict) 
Instance-level recall:  8.7     (soft) 
Instance-level recall:  51.11   (Levenshtein) 
Instance-level recall:  45.5    (RatcliffObershelp) 

======= Citation metadata ======= 

Evaluation on 1943 random PDF files out of 1943 PDF (ratio 1.0).

======= Strict Matching ======= (exact matches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

authors              97.52        82.83        73.71        78     
date                 98.96        93.02        81.45        86.85  
first_author         98.52        90.14        80.19        84.88  
id                   99           0            0            0      
inTitle              95.99        71.75        69.55        70.63  
issue                99.58        89.44        81.85        85.48  
page                 98.54        93.07        82.01        87.19  
title                97.01        78.5         71.96        75.09  
volume               99.22        95.08        87.16        90.95  

all fields           98.26        85.41        78.11        81.6    (micro average)
                     98.17        86.73        78.48        82.38   (macro average)


======== Soft Matching ======== (ignoring punctuation, case and space characters mismatches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

authors              97.6         83.4         74.22        78.54  
date                 98.96        93.02        81.45        86.85  
first_author         98.54        90.3         80.34        85.03  
id                   99           0            0            0      
inTitle              97.62        83.21        80.65        81.91  
issue                99.58        89.44        81.85        85.48  
page                 98.54        93.07        82.01        87.19  
title                98.52        89.77        82.29        85.86  
volume               99.22        95.08        87.16        90.95  

all fields           98.62        88.68        81.11        84.73   (micro average)
                     98.57        89.66        81.24        85.23   (macro average)


==== Levenshtein Matching ===== (Minimum Levenshtein distance at 0.8)

===== Field-level results =====

label                accuracy     precision    recall       f1     

authors              98.33        88.76        78.99        83.59  
date                 98.96        93.02        81.45        86.85  
first_author         98.56        90.41        80.44        85.13  
id                   99           0            0            0      
inTitle              97.75        84.15        81.56        82.84  
issue                99.58        89.44        81.85        85.48  
page                 98.54        93.07        82.01        87.19  
title                98.94        92.88        85.14        88.84  
volume               99.22        95.08        87.16        90.95  

all fields           98.76        90           82.32        85.99   (micro average)
                     98.73        90.85        82.32        86.36   (macro average)


= Ratcliff/Obershelp Matching = (Minimum Ratcliff/Obershelp similarity at 0.95)

===== Field-level results =====

label                accuracy     precision    recall       f1     

authors              97.89        85.57        76.15        80.58  
date                 98.96        93.02        81.45        86.85  
first_author         98.52        90.16        80.21        84.89  
id                   99           0            0            0      
inTitle              97.42        81.78        79.27        80.51  
issue                99.58        89.44        81.85        85.48  
page                 98.54        93.07        82.01        87.19  
title                98.81        91.9         84.24        87.91  
volume               99.22        95.08        87.16        90.95  

all fields           98.66        89.05        81.44        85.08   (micro average)
                     98.62        90           81.54        85.54   (macro average)

===== Instance-level results =====

Total expected instances:               90125
Total extracted instances:              88888
Total correct instances:                37406 (strict) 
Total correct instances:                48634 (soft) 
Total correct instances:                53051 (Levenshtein) 
Total correct instances:                49857 (RatcliffObershelp) 

Instance-level precision:       42.08 (strict) 
Instance-level precision:       54.71 (soft) 
Instance-level precision:       59.68 (Levenshtein) 
Instance-level precision:       56.09 (RatcliffObershelp) 

Instance-level recall:  41.5    (strict) 
Instance-level recall:  53.96   (soft) 
Instance-level recall:  58.86   (Levenshtein) 
Instance-level recall:  55.32   (RatcliffObershelp) 

Instance-level f-score: 41.79 (strict) 
Instance-level f-score: 54.34 (soft) 
Instance-level f-score: 59.27 (Levenshtein) 
Instance-level f-score: 55.7 (RatcliffObershelp) 

Matching 1 :    64906

Matching 2 :    4616

Matching 3 :    2742

Matching 4 :    690

Total matches : 72954


======= Fulltext structures ======= 

Evaluation on 1943 random PDF files out of 1943 PDF (ratio 1.0).

======= Strict Matching ======= (exact matches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

figure_title         96.72        30.53        23.28        26.42  
reference_citation   58.52        56.72        58.03        57.37  
reference_figure     94.5         60.23        60.59        60.41  
reference_table      98.97        79.44        81.92        80.66  
section_title        94.53        75.83        65.73        70.42  
table_title          98.81        56.85        51.08        53.81  

all fields           90.34        59.55        58.86        59.2    (micro average)
                     90.34        59.94        56.77        58.18   (macro average)


======== Soft Matching ======== (ignoring punctuation, case and space characters mismatches)

===== Field-level results =====

label                accuracy     precision    recall       f1     

figure_title         98.67        82.53        62.92        71.4   
reference_citation   61.07        60.87        62.27        61.56  
reference_figure     94.44        61.41        61.78        61.59  
reference_table      98.96        79.97        82.46        81.2   
section_title        95.18        80.53        69.81        74.79  
table_title          99.51        86.32        77.56        81.71  

all fields           91.3         65.08        64.32        64.7    (micro average)
                     91.3         75.27        69.47        72.04   (macro average)


************************************************************************************
COUNTER: org.grobid.core.engines.counters.TableRejectionCounters
************************************************************************************
------------------------------------------------------------------------------------
  CANNOT_PARSE_LABEL_TO_INT:          160
  CONTENT_SIZE_TOO_SMALL:             109
  CONTENT_WIDTH_TOO_SMALL:            15
  FEW_TOKENS_IN_CONTENT:              1
  EMPTY_LABEL_OR_HEADER_OR_CONTENT:   2203
  HEADER_NOT_STARTS_WITH_TABLE_WORD:  203
  HEADER_NOT_CONSECUTIVE:             572
  HEADER_AND_CONTENT_DIFFERENT_PAGES: 4
  HEADER_AND_CONTENT_INTERSECT:       640
  FEW_TOKENS_IN_HEADER:               5
====================================================================================

************************************************************************************
COUNTER: org.grobid.core.engines.counters.ReferenceMarkerMatcherCounters
************************************************************************************
------------------------------------------------------------------------------------
  UNMATCHED_REF_MARKERS:                    9267
  MATCHED_REF_MARKERS_AFTER_POST_FILTERING: 1581
  STYLE_AUTHORS:                            37431
  STYLE_NUMBERED:                           53254
  MANY_CANDIDATES:                          3829
  MANY_CANDIDATES_AFTER_POST_FILTERING:     292
  NO_CANDIDATES:                            17069
  INPUT_REF_STRINGS_CNT:                    93230
  MATCHED_REF_MARKERS:                      119466
  NO_CANDIDATES_AFTER_POST_FILTERING:       1854
  STYLE_OTHER:                              2545
====================================================================================

************************************************************************************
COUNTER: org.grobid.core.engines.label.TaggingLabelImpl
************************************************************************************
------------------------------------------------------------------------------------
  CITATION_TITLE:           84183
  NAME-HEADER_MIDDLENAME:   4236
  TABLE_FIGDESC:            5859
  NAME-HEADER_SURNAME:      10937
  NAME-CITATION_OTHER:      419182
  CITATION_BOOKTITLE:       3881
  FULLTEXT_SECTION_MARKER:  4
  CITATION_NOTE:            11406
  FULLTEXT_CITATION_MARKER: 182208
  FULLTEXT_TABLE_MARKER:    14891
  CITATION_WEB:             1366
  TABLE_LABEL:              3367
  FULLTEXT_SECTION:         51464
  NAME-HEADER_FORENAME:     11120
  TABLE_CONTENT:            5872
  CITATION_COLLABORATION:   153
  CITATION_ISSUE:           16366
  CITATION_JOURNAL:         78190
  NAME-CITATION_SURNAME:    320345
  TABLE_FIGURE_HEAD:        4723
  FULLTEXT_EQUATION_MARKER: 1829
  CITATION_OTHER:           432855
  FULLTEXT_FIGURE_MARKER:   38655
  CITATION_TECH:            246
  FIGURE_CONTENT:           3455
  FIGURE_LABEL:             5435
  FULLTEXT_EQUATION_LABEL:  1859
  FULLTEXT_EQUATION:        3882
  CITATION_DATE:            86178
  CITATION_AUTHOR:          86398
  FULLTEXT_FIGURE:          15142
  FULLTEXT_TABLE:           11408
  CITATION_EDITOR:          2485
  FULLTEXT_OTHER:           411
  NAME-HEADER_OTHER:        12546
  FIGURE_FIGDESC:           6687
  NAME-HEADER_SUFFIX:       11
  CITATION_VOLUME:          75885
  CITATION_LOCATION:        7017
  NAME-CITATION_SUFFIX:     544
  NAME-HEADER_TITLE:        480
  CITATION_INSTITUTION:     931
  CITATION_PAGES:           79522
  NAME-HEADER_MARKER:       7273
  NAME-CITATION_FORENAME:   309995
  CITATION_PUBLISHER:       4564
  NAME-CITATION_MIDDLENAME: 61254
  CITATION_PUBNUM:          2909
  FULLTEXT_PARAGRAPH:       375210
  FIGURE_FIGURE_HEAD:       9096
====================================================================================
====================================================================================

